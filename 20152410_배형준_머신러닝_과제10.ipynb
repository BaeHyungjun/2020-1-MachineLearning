{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20152410 배형준 머신러닝 과제10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:22.970240Z",
     "start_time": "2020-05-30T19:21:20.875536Z"
    }
   },
   "outputs": [],
   "source": [
    "# library import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:23.093164Z",
     "start_time": "2020-05-30T19:21:23.085166Z"
    }
   },
   "outputs": [],
   "source": [
    "# set my local working directory\n",
    "\n",
    "import os\n",
    "\n",
    "directory = 'C:\\\\Users\\\\golds\\\\Desktop\\\\중앙대학교\\\\2020-1 4학년 1학기\\\\머신러닝'\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:24.558254Z",
     "start_time": "2020-05-30T19:21:23.182109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
       "0    7    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    2    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    4    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "filename = './과제10/mnist.csv'\n",
    "mnist = pd.read_csv(filename, header=None)\n",
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:25.334772Z",
     "start_time": "2020-05-30T19:21:25.258836Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert data type from pd.DataFrame to np.array\n",
    "\n",
    "label = np.array(mnist.iloc[:, 0]).reshape(-1, 1)\n",
    "data = np.array(mnist.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Normalization class\n",
    "\n",
    "행 방향으로 정규화 : 한 행에서 (하나의 숫자 그림에서) 가장 작은 값이 0, 가장 큰 값이 1이 되도록 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:26.048332Z",
     "start_time": "2020-05-30T19:21:26.026344Z"
    }
   },
   "outputs": [],
   "source": [
    "# make class 'minmaxscaler'\n",
    "\n",
    "class minmaxscaler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.min_value = 0\n",
    "        self.max_value = 0\n",
    "        \n",
    "    def fit(self, X):\n",
    "        X = np.array(X)\n",
    "        self.min_value = np.min(X, axis=1)\n",
    "        self.max_value = np.where(np.max(X, axis=1) == 0, 1, np.max(X, axis=1))\n",
    "        # 행 별 최대 최소, 열 방향으로\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = np.array(X)\n",
    "        scaled = np.zeros(X.shape)\n",
    "        \n",
    "        for j in range(X.shape[0]):\n",
    "            scaled[j, :] = (X[j, :] - self.min_value[j]) / (self.max_value[j] - self.min_value[j])\n",
    "        \n",
    "        return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:26.718913Z",
     "start_time": "2020-05-30T19:21:26.052332Z"
    }
   },
   "outputs": [],
   "source": [
    "minmax_scaler_model = minmaxscaler()\n",
    "minmax_scaler_model.fit(data)\n",
    "data_scaled = minmax_scaler_model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Onehot encoding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:28.355711Z",
     "start_time": "2020-05-30T19:21:28.294750Z"
    }
   },
   "outputs": [],
   "source": [
    "class onehotencoding:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.unique = 0\n",
    "    \n",
    "    def fit(self, X):\n",
    "        X = np.array(X)\n",
    "        self.unique = np.unique(X)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = np.array(X)\n",
    "        m = X.shape[0]\n",
    "        n = self.unique.shape[0]\n",
    "    \n",
    "        empty = np.zeros((m, n))\n",
    "        \n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if X[i] == self.unique[j]:\n",
    "                    empty[i, j] = 1\n",
    "        \n",
    "        return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:29.718865Z",
     "start_time": "2020-05-30T19:21:29.177203Z"
    }
   },
   "outputs": [],
   "source": [
    "onehot_model = onehotencoding()\n",
    "onehot_model.fit(label)\n",
    "label_onehot = onehot_model.transform(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:30.358470Z",
     "start_time": "2020-05-30T19:21:30.346478Z"
    }
   },
   "outputs": [],
   "source": [
    "train_index = 1000\n",
    "\n",
    "train_label = label[:train_index]\n",
    "test_label = label[train_index:]\n",
    "\n",
    "label_onehot_train = label_onehot[:train_index, :]\n",
    "label_onehot_test = label_onehot[train_index:, :]\n",
    "\n",
    "data_scaled_train = data_scaled[:train_index, :]\n",
    "data_scaled_test = data_scaled[train_index:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Penalized Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:31.467787Z",
     "start_time": "2020-05-30T19:21:31.399837Z"
    }
   },
   "outputs": [],
   "source": [
    "class penalized_neural_network:\n",
    "\n",
    "    def __init__(self, learning_rate, error_bound, iteration, random_state,\n",
    "                 hidden_layer, number_node, fit_intercept, alpha):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.error_bound = error_bound\n",
    "        self.iteration = iteration\n",
    "        self.random_state = random_state\n",
    "        self.alpha = alpha # penalized hyper parameter\n",
    "        self.number_parameter = 0\n",
    "        \n",
    "        self.hidden_layer = hidden_layer # int\n",
    "        self.number_node = number_node # list of int\n",
    "        self.fit_intercept = fit_intercept # True or False\n",
    "        \n",
    "        self.record_train_cost = []\n",
    "        self.record_test_cost = []\n",
    "        self.record_train_accuracy = []\n",
    "        self.record_test_accuracy = []\n",
    "        \n",
    "        self.coef_list = []\n",
    "        self.train_predict = []\n",
    "        self.test_predict = []\n",
    "        self.last_gradient = []\n",
    "    \n",
    "    def sigmoid(self, X, coef):\n",
    "        z = np.dot(X, coef)\n",
    "        sigmoid_value = 1 / (1 + np.exp(-z))\n",
    "        \n",
    "        return sigmoid_value\n",
    "    \n",
    "    def cost(self, X, coef_list, onehot_label):\n",
    "        delta = 10**(-8)\n",
    "        m = X.shape[0]\n",
    "        temp = X\n",
    "        sigmoid_list = []\n",
    "        \n",
    "        # forward propagation\n",
    "        for coef in coef_list:    \n",
    "            sig = self.sigmoid(temp, coef)\n",
    "            sigmoid_list.append(sig)\n",
    "            \n",
    "            if self.fit_intercept == True:\n",
    "                temp = np.column_stack((np.ones((sig.shape[0], 1)), sig))\n",
    "            else:\n",
    "                temp = sig\n",
    "        \n",
    "        error_term = -np.mean(np.sum(onehot_label * np.log(sig + delta) + (1 - onehot_label) * np.log(1 - sig + delta), axis=1))\n",
    "        \n",
    "        l2_term = 0\n",
    "        for coef in coef_list:\n",
    "            temp = self.alpha * np.mean(coef**2) / 2\n",
    "            l2_term = l2_term + temp\n",
    "            \n",
    "        cost_value = error_term + l2_term\n",
    "        \n",
    "        return cost_value, sigmoid_list\n",
    "    \n",
    "    def gradient(self, X, coef_list, onehot_label, sigmoid_list):\n",
    "        m = X.shape[0]\n",
    "        delta_list = []\n",
    "        gradient_list = []\n",
    "        \n",
    "        add_constant_sigmoid = []\n",
    "        \n",
    "        for i in range(len(sigmoid_list)):\n",
    "            temp = np.column_stack((np.ones((sigmoid_list[i].shape[0], 1)), sigmoid_list[i]))\n",
    "            add_constant_sigmoid.append(temp)\n",
    "        \n",
    "        sigmoid_list.insert(0, X)\n",
    "        add_constant_sigmoid.insert(0, X)\n",
    "        \n",
    "        # backward propagation\n",
    "        for i in range(self.hidden_layer+1):\n",
    "            if i == 0:\n",
    "                delta_value = sigmoid_list[-1] - onehot_label\n",
    "                penarlized_term = self.alpha * coef_list[-1] / self.number_parameter\n",
    "                gradient_value = np.dot(add_constant_sigmoid[-2].T, delta_value) / m + penarlized_term\n",
    "                \n",
    "                delta_list.insert(0, delta_value)\n",
    "                gradient_list.insert(0, gradient_value)\n",
    "            \n",
    "            else:\n",
    "                delta_value = np.dot(delta_list[0], coef_list[-i][1:, :].T) * sigmoid_list[-i-1] * (1 - sigmoid_list[-i-1])\n",
    "                penarlized_term = self.alpha * coef_list[-i-1] / self.number_parameter\n",
    "                gradient_value = np.dot(add_constant_sigmoid[-i-2].T, delta_value) / m + penarlized_term\n",
    "                \n",
    "                delta_list.insert(0, delta_value)\n",
    "                gradient_list.insert(0, gradient_value)\n",
    "        \n",
    "        return gradient_list\n",
    "    \n",
    "    def predict(self, sigmoid_list, predict_type='class'):\n",
    "        output_layer = sigmoid_list[-1]\n",
    "        \n",
    "        if predict_type == 'class':\n",
    "            predict_value = np.argmax(output_layer, axis=1)\n",
    "        \n",
    "        elif predict_type == 'response':\n",
    "            predict_value = output_layer\n",
    "        \n",
    "        return predict_value\n",
    "    \n",
    "    def fit(self, X_train, Y_train, X_test, Y_test): # Y_train, Y_test는 onehotencoding이 완료된 데이터\n",
    "        X_train = np.array(X_train)\n",
    "        Y_train = np.array(Y_train)\n",
    "        X_test = np.array(X_test)\n",
    "        Y_test = np.array(Y_test)\n",
    "        m = X_train.shape[0]\n",
    "        n = X_train.shape[1]\n",
    "        q = X_test.shape[0]\n",
    "        p = Y_train.shape[1]\n",
    "        label_train = np.argmax(Y_train, axis=1).reshape(-1, 1) # train accuracy 계산하기 위한 label\n",
    "        label_test = np.argmax(Y_test, axis=1).reshape(-1, 1) # test accuracy 계산하기 위한 label\n",
    "        \n",
    "        self.number_node.insert(0, n)\n",
    "        self.number_node.append(p)\n",
    "        coef_list = []\n",
    "        \n",
    "        # fit_intercept\n",
    "        if self.fit_intercept == True:\n",
    "            number_node_with_intercept = []\n",
    "            \n",
    "            X_train = np.column_stack((np.ones((m, 1)), X_train))\n",
    "            X_test = np.column_stack((np.ones((q, 1)), X_test))\n",
    "            \n",
    "            for number in self.number_node:\n",
    "                number_node_with_intercept.append(number+1)\n",
    "                \n",
    "        else:\n",
    "            number_node_with_intercept = self.number_node\n",
    "        \n",
    "        # calculate number of parameters\n",
    "        number_parameter = 0\n",
    "        for i in range(len(number_node_with_intercept)-1):\n",
    "            temp = number_node_with_intercept[i]*number_node_with_intercept[i+1]\n",
    "            number_parameter = number_parameter + temp\n",
    "            \n",
    "        self.number_parameter = number_parameter\n",
    "        \n",
    "        # set initial parameters\n",
    "        np.random.seed(self.random_state) # for reproducibility\n",
    "        \n",
    "        for layer in range(self.hidden_layer+1):\n",
    "            temp_theta = np.random.randn(number_node_with_intercept[layer], self.number_node[layer+1])\n",
    "            coef_list.append(temp_theta)\n",
    "        \n",
    "        # check model fitting progress\n",
    "        import time\n",
    "        start = time.time()\n",
    "        \n",
    "        # model fitting\n",
    "        while True:\n",
    "            # calculate train and test cost\n",
    "            train_cost, train_sigmoid = self.cost(X_train, coef_list, Y_train)\n",
    "            test_cost, test_sigmoid = self.cost(X_test, coef_list, Y_test)\n",
    "            \n",
    "            self.record_train_cost.append(train_cost)\n",
    "            self.record_test_cost.append(test_cost)\n",
    "            \n",
    "            # calculate train and test accuracy\n",
    "            train_predict = self.predict(train_sigmoid, predict_type='class').reshape(-1, 1)\n",
    "            test_predict = self.predict(test_sigmoid, predict_type='class').reshape(-1, 1)\n",
    "            \n",
    "            train_accuarcy = np.mean(train_predict == label_train)\n",
    "            test_accuarcy = np.mean(test_predict == label_test)\n",
    "            \n",
    "            self.record_train_accuracy.append(train_accuarcy)\n",
    "            self.record_test_accuracy.append(test_accuarcy)\n",
    "            \n",
    "            # calculate gradient using back propagation and renew the parameters\n",
    "            gradient_list = self.gradient(X_train, coef_list, Y_train, train_sigmoid)\n",
    "            \n",
    "            for i in range(len(coef_list)):\n",
    "                coef_list[i] = coef_list[i] - self.learning_rate * gradient_list[i]\n",
    "\n",
    "            # stopping rules\n",
    "            length = len(self.record_train_accuracy)\n",
    "            \n",
    "            if length > self.iteration:\n",
    "                if self.record_train_accuracy[-2] - self.record_train_accuracy[-1] < self.error_bound:\n",
    "                    break\n",
    "            \n",
    "            # print model fitting progress\n",
    "            running_time = time.time() - start\n",
    "            minute = int(running_time // 60)\n",
    "            second = round(running_time % 60, 1)\n",
    "            \n",
    "            if length % 200 == 0:\n",
    "                print('Iter : {}, Running time : {}m {}s'.format(length, minute, second), end=', ')\n",
    "                print('Train accuracy : {}%, Test accuracy : {}%'.format(round(100*train_accuarcy, 2),\n",
    "                                                                         round(100*test_accuarcy), 2))\n",
    "                print('Train Cost : {}, Test Cost : {}\\n'.format(train_cost, test_cost))\n",
    "            \n",
    "            # error situation : too much iteration\n",
    "            if length > 100000:\n",
    "                print('반복 횟수가 너무 많습니다. Train Cost가 수렴하지 못했습니다. 학습률을 조정해보시기 바랍니다.')\n",
    "                break\n",
    "                \n",
    "        self.coef_list = coef_list\n",
    "        self.train_predict = train_predict\n",
    "        self.test_predict = test_predict\n",
    "        self.last_gradient = gradient_list\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T19:21:41.542186Z",
     "start_time": "2020-05-30T19:21:41.537191Z"
    }
   },
   "outputs": [],
   "source": [
    "model_neural_network = penalized_neural_network(learning_rate=2,\n",
    "                                                error_bound=10**(-7),\n",
    "                                                iteration=1000,\n",
    "                                                random_state=20152410,\n",
    "                                                hidden_layer=3,\n",
    "                                                number_node=[392, 196, 98],\n",
    "                                                alpha=10,\n",
    "                                                fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-30T19:21:42.984Z"
    }
   },
   "outputs": [],
   "source": [
    "model_neural_network.fit(X_train=data_scaled_train,\n",
    "                         Y_train=label_onehot_train,\n",
    "                         X_test=data_scaled_test,\n",
    "                         Y_test=label_onehot_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result record\n",
    "\n",
    "##### 1번 시도 : learning_rate=1, alpha=1, hidden_layer=2, number_node=[196, 49]\n",
    "\n",
    "Iter : 1000, Running time : 4m 54.1s, Train accuracy : 100.0%, Test accuracy : 77.0%\n",
    "\n",
    "Train Cost : 2.1335127255917756, Test Cost : 3.6063976066367505\n",
    "\n",
    "##### 2번 시도 : learning_rate=2, alpha=10, hidden_layer=3, number_node=[392, 196, 98]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source of plot of the classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 10\n",
    "size_row = 28\n",
    "size_col = 28\n",
    "\n",
    "train_cor_index = []\n",
    "train_mis_index = []\n",
    "\n",
    "test_cor_index = []\n",
    "test_mis_index = []\n",
    "\n",
    "for i in range(len(train_label)):\n",
    "    if model_neural_network.train_predict[i] == train_label[i]:\n",
    "        train_cor_index.append(i)\n",
    "    else:\n",
    "        train_mis_index.append(i)\n",
    "\n",
    "for j in range(len(test_label)):\n",
    "    if model_neural_network.test_predict[j] == test_label[j]:\n",
    "        test_cor_index.append(j)\n",
    "    else:\n",
    "        test_mis_index.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_index = test_cor_index[:number]\n",
    "cor_label = test_label[cor_index]\n",
    "cor_pred = model_neural_network.test_predict[cor_index]\n",
    "cor_data = data_scaled_test[cor_index, :]\n",
    "\n",
    "mis_index = test_mis_index[:number]\n",
    "mis_label = test_label[mis_index]\n",
    "mis_pred = model_neural_network.test_predict[mis_index]\n",
    "mis_data = data_scaled_test[mis_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_data_list = []\n",
    "mis_data_list = []\n",
    "\n",
    "for a in range(number):\n",
    "    cor_pixel = cor_data[a, :].reshape(size_row, size_col)\n",
    "    mis_pixel = mis_data[a, :].reshape(size_row, size_col)\n",
    "    \n",
    "    cor_data_list.append(cor_pixel)\n",
    "    mis_data_list.append(mis_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincost = model_neural_network.record_train_cost\n",
    "testcost = model_neural_network.record_test_cost\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(traincost, 'b', label='train')\n",
    "plt.plot(testcost, 'r', label='test')\n",
    "plt.title('Loss curve of train and test', fontsize=25)\n",
    "plt.xlabel('iteration', fontsize=15)\n",
    "plt.ylabel('loss', fontsize=15)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot the accuracy curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainacc100 = 100*np.array(model_neural_network.record_train_accuracy)\n",
    "testacc100 = 100*np.array(model_neural_network.record_test_accuracy)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(trainacc100, 'b', label='train')\n",
    "plt.plot(testacc100, 'r', label='test')\n",
    "plt.title('Accuracy curve of train and test', fontsize=25)\n",
    "plt.xlabel('iteration', fontsize=15)\n",
    "plt.ylabel('accuracy (%)', fontsize=15)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Plot the accuracy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traina = round(trainacc100[-1], 2)\n",
    "testa = round(testacc100[-1], 2)\n",
    "trainb = traincost[-1]\n",
    "testb = testcost[-1]\n",
    "\n",
    "print('Final train accuracy : {}%, Final train loss : {}'.format(traina, trainb))\n",
    "print('Final test accuracy : {}%, Final test loss : {}'.format(testa, testb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plot the classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1 Plot of right-predicted classification caes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axes1 = plt.subplots(2, 5, figsize=(15, 7.5))\n",
    "axes1 = axes1.ravel()\n",
    "\n",
    "for p in range(number):\n",
    "    axes1[p].imshow(cor_data_list[p], cmap='Greys', interpolation=None)\n",
    "    axes1[p].set_title('{} predicted as {}'.format(int(cor_label[p]), int(cor_pred[p])), fontsize=15)\n",
    "    axes1[p].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2 Plot of mis-predicted classification caes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axes2 = plt.subplots(2, 5, figsize=(15, 7.5))\n",
    "axes2 = axes2.ravel()\n",
    "\n",
    "for p in range(number):\n",
    "    axes2[p].imshow(mis_data_list[p], cmap='Greys', interpolation=None)\n",
    "    axes2[p].set_title('{} predicted as {}'.format(int(mis_label[p]), int(mis_pred[p])), fontsize=15)\n",
    "    axes2[p].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
